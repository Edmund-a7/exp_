# IAM Agent Inference Configuration (ID-only memory)
# Scene memory is disabled for single-scene benchmark validation.

# Architecture
denoising_step_list:
  - 1000
  - 750
  - 500
  - 250
warp_denoising_step: true
num_frame_per_block: 3
model_name: Wan2.1-T2V-1.3B
model_kwargs:
  local_attn_size: 12
  timestep_shift: 5.0
  sink_size: 3
  bank_size: 6
  record_interval: 3
  SMA: true
  tcat_enabled: false
  tcat_sink_k: 1
  tcat_mem_k: 2
  tcat_local_k: 3
  tcat_local_near: 3
  tcat_ema_alpha: 0.3
  # HSA: hierarchical sparse attention (sink+memory frame top-k + block top-k_b)
  hsa_enabled: false
  hsa_frame_top_k: 2
  hsa_frame_min_sink: 1
  hsa_frame_min_mem: 1
  hsa_local_far_frames: 3
  hsa_local_near_frames: 3
  hsa_block_size: 64
  hsa_block_keep_ratio: 0.35
  hsa_block_min_blocks: 1

# Inference
data_path: prompts/interactive_example.jsonl
output_folder: videos/iam_interactive_id_only
inference_iter: -1
num_output_frames: 240
use_ema: false
seed: 1
num_samples: 1
save_with_index: true
switch_frame_indices: 40, 80, 120, 160, 200
global_sink: true
context_noise: 0

# SPT
spt_enabled: true
spt:
  scheduler_type: adaptive
  base_scheduler: cosine
  min_window: 3
  max_window: 15
  window_frames: 9
  delay_frames: 3
  steepness: 6.0
  frames_per_chunk: 3

# Continuity options
keep_bank_on_spt_switch: true

# Checkpoints
generator_ckpt: checkpoints/base.pt
lora_ckpt: checkpoints/lora.pt

# LoRA Adapter
adapter:
  type: "lora"
  rank: 256
  alpha: 256
  dropout: 0.0
  dtype: "bfloat16"
  verbose: false

# IAM Agent Settings
llm_model_path: ../Qwen3-0.6B
max_memory_frames: 3
save_dir: data/agent_frames
use_vllm: true
enable_scene_memory: false
entity_memory_weight: 1.0
scene_memory_weight: 0.0
scene_skip_threshold: 0.22
min_id_memory_frames_multi_entity: 2
min_scene_memory_frames: 1
scene_budget_token_threshold: 4
