# IAM Agent Inference Configuration (ID-only memory)
# Scene memory is disabled for single-scene benchmark validation.

# Architecture
denoising_step_list:
  - 1000
  - 750
  - 500
  - 250
warp_denoising_step: true
num_frame_per_block: 3
model_name: Wan2.1-T2V-1.3B
model_kwargs:
  local_attn_size: 12
  timestep_shift: 5.0
  sink_size: 3
  bank_size: 6
  record_interval: 3
  SMA: true
  # HSA: hierarchical sparse attention (sink+memory frame top-k + block top-k_b)
  hsa_enabled: true
  hsa_frame_top_k: 2
  hsa_frame_min_sink: 1
  hsa_frame_min_mem: 1
  hsa_local_far_frames: 6
  hsa_local_near_frames: 3
  hsa_block_size: 64
  hsa_block_keep_ratio: 0.35
  hsa_block_min_blocks: 1

# Inference
data_path: prompts/interactive_example.jsonl
output_folder: videos/iam_interactive_id_only
inference_iter: -1
num_output_frames: 240
use_ema: false
seed: 1
num_samples: 1
save_with_index: true
switch_frame_indices: 40, 80, 120, 160, 200
global_sink: true
context_noise: 0

# SPT
spt_enabled: true
spt:
  scheduler_type: adaptive
  base_scheduler: cosine
  min_window: 3
  max_window: 15
  window_frames: 9
  delay_frames: 3
  steepness: 6.0
  frames_per_chunk: 3

# Continuity options
keep_bank_on_spt_switch: true

# Checkpoints
generator_ckpt: checkpoints/base.pt
lora_ckpt: checkpoints/lora.pt

# LoRA Adapter
adapter:
  type: "lora"
  rank: 256
  alpha: 256
  dropout: 0.0
  dtype: "bfloat16"
  verbose: false

# IAM Agent Settings
llm_model_path: ../Qwen3-0.6B
max_memory_frames: 3
save_dir: data/agent_frames
use_vllm: true
min_id_memory_frames_multi_entity: 2
# Prompt-level HSA sparse schedule
hsa_prompt_schedule_enabled: true
hsa_prompt_schedule_mode: increase   # increase: 0.3->0.5, decrease: 0.5->0.3
hsa_prompt_keep_ratio_min: 0.3
hsa_prompt_keep_ratio_max: 0.5
hsa_chunk0_force_sma: true
