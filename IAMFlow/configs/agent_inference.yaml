# IAM Agent Single Prompt Inference Configuration
# Based on inference.yaml with IAM-specific settings

# Architecture
denoising_step_list:
- 1000
- 750
- 500
- 250
warp_denoising_step: true
num_frame_per_block: 3
model_name: Wan2.1-T2V-1.3B
model_kwargs:
  local_attn_size: 12
  timestep_shift: 5.0
  sink_size: 3
  bank_size: 3
  record_interval: 3
  SMA: False  # Disabled when using TCAT
  # TCAT: Temporal Coverage Aware Top-k
  tcat_enabled: True
  tcat_sink_k: 1   # Select top-1 from Sink region (3 chunks)
  tcat_mem_k: 2    # Select top-2 from Mem region (3 chunks)
  tcat_local_k: 3  # Select top-3 from Local region (9 chunks)

# Inference
data_path: prompts/vidprom_filtered_extended.txt
output_folder: videos/iam_single_prompt
inference_iter: -1
num_output_frames: 120
use_ema: false
seed: 0
num_samples: 1
save_with_index: true
global_sink: true
context_noise: 0

# Checkpoints
generator_ckpt: checkpoints/base.pt
lora_ckpt: checkpoints/lora.pt

# LoRA Adapter
adapter:
  type: "lora"
  rank: 256
  alpha: 256
  dropout: 0.0
  dtype: "bfloat16"
  verbose: false

# IAM Agent Settings (optional for single prompt, but available)
llm_model_path: ../Qwen3-0.6B
max_memory_frames: 3
save_dir: data/agent_frames
