# IAM Agent Inference Configuration
# Based on interactive_inference.yaml with IAM-specific settings

# Architecture
denoising_step_list:
- 1000
- 750
- 500
- 250
warp_denoising_step: true
num_frame_per_block: 3
model_name: Wan2.1-T2V-1.3B
model_kwargs:
  local_attn_size: 12
  timestep_shift: 5.0
  sink_size: 3
  bank_size: 6
  record_interval: 3
  SMA: True   # Enabled (TCAT disabled)
  # TCAT: Temporal Coverage Aware Top-k
  tcat_enabled: False
  tcat_sink_k: 1   # Select top-1 from Sink region (3 chunks)
  tcat_mem_k: 2    # Select top-2 from Mem region (3 chunks)
  tcat_local_k: 3  # Select top-3 from Local-far region (6 chunks)
  tcat_local_near: 3  # Preserve last 3 chunks (most recent frames)
  tcat_ema_alpha: 0.3  # EMA smoothing factor (0=disabled)

# Inference
data_path: prompts/interactive_example.jsonl
output_folder: videos/iam_interactive
inference_iter: -1
num_output_frames: 240
use_ema: false
seed: 1
num_samples: 1
save_with_index: true
switch_frame_indices: 40, 80, 120, 160, 200
global_sink: true
context_noise: 0

# SPT: Soft Prompt Transition
spt_enabled: true  # Set to true to enable soft transition (disables recache)
spt:
  scheduler_type: adaptive  # linear, cosine, sigmoid, step, adaptive
  base_scheduler: cosine    # Adaptive only: 底层调度曲线
  min_window: 3             # Adaptive only: 最短过渡窗口 (1 chunk)
  max_window: 15            # Adaptive only: 最长过渡窗口 (5 chunks)
  window_frames: 9          # Non-adaptive: 固定过渡窗口
  delay_frames: 3           # Delay before blending starts (1 chunk)
  steepness: 6.0            # Sigmoid scheduler only
  frames_per_chunk: 3       # Step scheduler only
keep_bank_on_spt_switch: true  # 保留切换前记忆，减少边界帧跳变

# Checkpoints
generator_ckpt: checkpoints/base.pt
lora_ckpt: checkpoints/lora.pt

# LoRA Adapter
adapter:
  type: "lora"
  rank: 256
  alpha: 256
  dropout: 0.0
  dtype: "bfloat16"
  verbose: false

# IAM Agent Settings (can be overridden via command line)
llm_model_path: ../Qwen3-0.6B
max_memory_frames: 3
save_dir: data/agent_frames
use_vllm: true  # 使用 vLLM 加速 LLM 推理 (需要安装 vllm)
enable_scene_memory: true  # false 时只使用 id-memory
entity_memory_weight: 0.72
scene_memory_weight: 0.28
scene_skip_threshold: 0.22
min_id_memory_frames_multi_entity: 2
min_scene_memory_frames: 1
scene_budget_token_threshold: 4
